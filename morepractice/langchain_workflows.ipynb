{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "658ab495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full form of **RCB** is **Royal Challengers Bangalore**. It is a franchise cricket team that plays in the Indian Premier League (IPL), based in Bangalore, Karnataka. The team is well-known for its strong fanbase and association with players like Virat Kohli, AB de Villiers, and others over the years.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Load Azure OpenAI credentials\n",
    "end_point = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")   \n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\") \n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")     \n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT_4O_DEPLOYMENT_NAME\") \n",
    "\n",
    "# Initialize LangChain ChatOpenAI with Azure creds\n",
    "client = AzureChatOpenAI(\n",
    "    openai_api_version=api_version,\n",
    "    azure_endpoint=end_point,\n",
    "    openai_api_key= api_key,\n",
    "    deployment_name = deployment_name\n",
    ")\n",
    "\n",
    "\n",
    "response = client.invoke([HumanMessage(content=\"What is full form of rcb?\")])\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16277ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework designed to help developers build applications that leverage the power of **large language models (LLMs)**. It provides tools, components, and integrations to simplify the process of building complex applications that involve natural language processing, understanding, reasoning, and generation.\n",
      "\n",
      "LangChain is especially useful in cases where you need to combine LLMs with external data sources (like databases or APIs), incorporate memory to maintain context across user interactions, or chain together a series of tasks to achieve more complex workflows.\n",
      "\n",
      "### Key Features of LangChain:\n",
      "1. **Components:**\n",
      "   - **Prompt Templates:** Frameworks for constructing dynamic and reusable prompts for LLMs.\n",
      "   - **Chains:** A way to sequence multiple operations, such as querying an LLM and processing its response, to achieve complex tasks.\n",
      "   - **Memory:** Methods to store and retrieve conversational context or intermediate state, enhancing applications like chatbots.\n",
      "   - **Agents:** Components that enable an LLM to make decisions about which tools or actions to use in real-time.\n",
      "   - **Retrievers:** Tools for accessing knowledge from external sources, such as structured databases, unstructured documents, or web APIs.\n",
      "   - **Document Loaders:** Functions to easily upload and process various types of documents (PDFs, text, etc.) for use in applications.\n",
      "\n",
      "2. **Tool Integration:**\n",
      "   LangChain provides prebuilt integrations with APIs, knowledge bases, and external tools like databases, search engines, and Python scripts. This makes it possible for your language model to interact with real-world data.\n",
      "\n",
      "3. **Real-World Use Cases:**\n",
      "   - Conversational AI/chatbots\n",
      "   - Question answering systems\n",
      "   - Generative applications (e.g., content creation)\n",
      "   - Code generation tools\n",
      "   - Autonomous agents (tools that can reason, decide, and act)\n",
      "\n",
      "4. **Flexibility and Modularity:**\n",
      "   The modular structure of LangChain allows developers to focus on specific aspects of their application while relying on LangChain to handle the complexity of interacting with LLMs.\n",
      "\n",
      "### Why Developers Use LangChain:\n",
      "LangChain is particularly powerful because it abstracts a lot of the complexity involved in creating advanced LLM-based applications. By providing standard components, workflows, and integrations, it allows developers to focus on building solutions without reinventing the wheel.\n",
      "\n",
      "For example:\n",
      "- Instead of manually managing API calls to OpenAI or another LLM provider, LangChain allows you to define how queries are handled, what prompts to use, and how data should be processed.\n",
      "- If your application involves working with external knowledge or maintaining context, LangChain provides built-in solutions to address these needs.\n",
      "\n",
      "### Supported Models and Environments:\n",
      "LangChain supports numerous large language models, including OpenAIâ€™s GPT-3/4, as well as other providers like Anthropic, Cohere, and Hugging Face. It can also be used for applications written in Python, and there is growing support for JavaScript/TypeScript. \n",
      "\n",
      "In essence, LangChain is a powerful toolkit that unlocks the full potential of language models, enabling developers to build more robust, intelligent, and complex AI systems.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Load Azure OpenAI credentials\n",
    "end_point = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")   \n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\") \n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")     \n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT_4O_DEPLOYMENT_NAME\") \n",
    "\n",
    "# Initialize LangChain ChatOpenAI with Azure creds\n",
    "client = AzureChatOpenAI(\n",
    "    openai_api_version=api_version,\n",
    "    azure_endpoint=end_point,\n",
    "    openai_api_key= api_key,\n",
    "    deployment_name = deployment_name\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variable = [\"question\"],\n",
    "    template = \"You are a helpful AI assistant. Answer the following:{question}\"\n",
    ")\n",
    "\n",
    "chain = prompt | client\n",
    "\n",
    "response = chain.invoke({\"question\":\"what is langchain?\"})\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e899c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI assistant providing answers to user queries.\n",
      "Human: Who won the FIFA World Cup 2022?\u001b[0m\n",
      "The **2022 FIFA World Cup** was won by **Argentina**. They defeated **France** in a thrilling final that ended 3-3 after extra time and was decided via a penalty shootout, which Argentina won 4-2. This victory marked Argentina's third World Cup title, with their previous wins coming in 1978 and 1986. The tournament was notable for the stellar performances of Lionel Messi, who played a key role in leading Argentina to victory and was awarded the **Golden Ball** as the tournament's best player.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "First Response: The **2022 FIFA World Cup** was won by **Argentina**. They defeated **France** in a thrilling final that ended 3-3 after extra time and was decided via a penalty shootout, which Argentina won 4-2. This victory marked Argentina's third World Cup title, with their previous wins coming in 1978 and 1986. The tournament was notable for the stellar performances of Lionel Messi, who played a key role in leading Argentina to victory and was awarded the **Golden Ball** as the tournament's best player.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI assistant providing answers to user queries.\n",
      "Human: Who won the FIFA World Cup 2022?\n",
      "AI: The **2022 FIFA World Cup** was won by **Argentina**. They defeated **France** in a thrilling final that ended 3-3 after extra time and was decided via a penalty shootout, which Argentina won 4-2. This victory marked Argentina's third World Cup title, with their previous wins coming in 1978 and 1986. The tournament was notable for the stellar performances of Lionel Messi, who played a key role in leading Argentina to victory and was awarded the **Golden Ball** as the tournament's best player.\n",
      "Human: Who was the captain of the winning team?\u001b[0m\n",
      "The captain of the winning team, **Argentina**, in the **2022 FIFA World Cup** was **Lionel Messi**. \n",
      "\n",
      "Messi delivered a historic performance throughout the tournament and played a pivotal role in leading Argentina to their third World Cup title. In the final, he scored twice and also converted his penalty in the shootout against France. This victory cemented his legacy as one of the greatest football players of all time.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Second Response: The captain of the winning team, **Argentina**, in the **2022 FIFA World Cup** was **Lionel Messi**. \n",
      "\n",
      "Messi delivered a historic performance throughout the tournament and played a pivotal role in leading Argentina to their third World Cup title. In the final, he scored twice and also converted his penalty in the shootout against France. This victory cemented his legacy as one of the greatest football players of all time.\n"
     ]
    }
   ],
   "source": [
    "#May be deprecated code\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load Azure OpenAI credentials\n",
    "end_point = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")   \n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\") \n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")     \n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT_4O_DEPLOYMENT_NAME\") \n",
    "\n",
    "# Initialize LangChain ChatOpenAI with Azure creds\n",
    "client = AzureChatOpenAI(\n",
    "    openai_api_version=api_version,\n",
    "    azure_endpoint=end_point,\n",
    "    openai_api_key= api_key,\n",
    "    deployment_name = deployment_name,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "\n",
    "# Define a chat prompt with memory\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a helpful AI assistant providing answers to user queries.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Memory Configuration\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Create the chain\n",
    "conversation = LLMChain(\n",
    "    llm=client,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "\n",
    "response1 = conversation({\"question\": \"Who won the FIFA World Cup 2022?\"})\n",
    "print(\"\\nFirst Response:\", response1[\"text\"])\n",
    "\n",
    "# ðŸ§  Second Interaction (Remembers previous conversation)\n",
    "response2 = conversation({\"question\": \"Who was the captain of the winning team?\"})\n",
    "print(\"\\nSecond Response:\", response2[\"text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43600d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f60b289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: The **Los Angeles Dodgers** won the 2020 World Series. They defeated the **Tampa Bay Rays** in six games to claim their first championship since 1988. The series took place at the neutral site of Globe Life Field in Arlington, Texas, due to the COVID-19 pandemic. Dodgers shortstop **Corey Seager** was named the World Series MVP.\n"
     ]
    }
   ],
   "source": [
    "#newer version code\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load Azure OpenAI credentials\n",
    "end_point = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT_4O_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Initialize AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=api_version,\n",
    "    azure_endpoint=end_point,\n",
    "    openai_api_key=api_key,\n",
    "    deployment_name=deployment_name,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "# Define a chat prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant providing answers to user queries.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# âœ… Runnable chain (new style)\n",
    "chain = prompt | llm\n",
    "\n",
    "# Example run\n",
    "response = chain.invoke({\"chat_history\": [], \"question\": \"Who won the world series in 2020?\"})\n",
    "print(\"\\nAssistant:\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6d133a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from wikipedia) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11704 sha256=c91e9b89e11101d8ca6462d1117ed8fd2cb6d13ec71c7cfdf7401440b48e3e75\n",
      "  Stored in directory: c:\\users\\jhanvi\\appdata\\local\\pip\\cache\\wheels\\63\\47\\7c\\a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65462076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.75)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.34)\n",
      "Collecting requests<3,>=2.32.5 (from langchain-community)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.20)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (23.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from langsmith>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.21.0)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.32.5->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.32.5->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.32.5->langchain-community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.32.5->langchain-community) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jhanvi\\appdata\\roaming\\python\\python312\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\jhanvi\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.0.0)\n",
      "Using cached langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, typing-inspect, requests, marshmallow, httpx-sse, dataclasses-json, pydantic-settings, langchain-community\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: pydantic-settings\n",
      "    Found existing installation: pydantic-settings 2.6.1\n",
      "    Uninstalling pydantic-settings-2.6.1:\n",
      "      Successfully uninstalled pydantic-settings-2.6.1\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.29 marshmallow-3.26.1 pydantic-settings-2.10.1 requests-2.32.3 typing-inspect-0.9.0 typing-inspection-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "460e427e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n",
      "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "{'query': {'description': 'query to look up on wikipedia', 'title': 'Query', 'type': 'string'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Page: Royal Challengers Bengaluru\\nSummary: Royal Challengers Bengaluru, formerly Royal Challengers Bangalore, also known as RCB, are a professional Twenty20 cricket team based in Bengaluru, Karnataka, that competes in the Indian Premier League (IPL). Founded in 2008 by United Spirits, the team's home ground is M. Chinnaswamy Stadium. They won their first title in 2025. The team finished as the runners-up on three occasions: in 2009, 2011, and 2016. They have also qualified for the playoffs in ten of the eighteen seasons.\\nAs of 2025, the team is captained by Rajat Patidar and coached by Andy Flower. The franchise has competed in the Champions League, finishing as runners-up in the 2011 season. As of 2024, RCB was valued at $117 million, making it one of the most valuable franchises.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=1000)\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "print(tool.name)\n",
    "print(tool.description)\n",
    "print(tool.args)\n",
    "\n",
    "tool.run({\"query\": \"RCB\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63a239d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jhanvi\\AppData\\Local\\Temp\\ipykernel_23476\\1107383616.py:17: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import AzureChatOpenAI``.\n",
      "  llm = AzureChatOpenAI(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are some creative and powerful name suggestions for a gaming laptop brand:\n",
      "\n",
      "1. **PixelForge**\n",
      "2. **GameVortex**\n",
      "3. **ShadowCore**\n",
      "4. **TitanByte**\n",
      "5. **InfernoGear**\n",
      "6. **PulseRift**\n",
      "7. **WarpDrive**\n",
      "8. **CrimsonRig**\n",
      "9. **PhantomX**\n",
      "10. **LevelUp Laptops**\n",
      "11. **HyperHavoc**\n",
      "12. **Overclocked**\n",
      "13. **SpectraEdge**\n",
      "14. **NextVerse**\n",
      "15. **IronPixel**\n",
      "\n",
      "Each of these names conveys performance, precision, and the immersive experience gamers look for. Let me know if you'd like me to refine the suggestions further!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load Azure OpenAI credentials\n",
    "end_point = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT_4O_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Initialize AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=api_version,\n",
    "    azure_endpoint=end_point,\n",
    "    openai_api_key=api_key,\n",
    "    deployment_name=deployment_name,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=ChatPromptTemplate.from_template(\"Suggest a company name for {product}.\")\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "result = chain.run({\"product\": \"gaming laptop\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5eb58b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': 'gaming laptop', 'company_name': 'GameForge', 'description': 'Gameforge is a leading German video game publisher and developer specializing in free-to-play online games, including MMORPGs and browser-based titles.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load Azure OpenAI credentials\n",
    "end_point = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT_4O_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Initialize AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=api_version,\n",
    "    azure_endpoint=end_point,\n",
    "    openai_api_key=api_key,\n",
    "    deployment_name=deployment_name,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "chain_one = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=ChatPromptTemplate.from_template(\"Give me just one word output. I need a company name for {product}.\"),\n",
    "    output_key=\"company_name\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=ChatPromptTemplate.from_template(\"Describe {company_name} in one sentence.\"),\n",
    "    output_key=\"description\"\n",
    ")\n",
    "\n",
    "# Create a simple SequentialChain\n",
    "simple_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two],\n",
    "    input_variables=[\"product\"],\n",
    "    output_variables=[\"company_name\", \"description\"]\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "result = simple_chain({\"product\": \"gaming laptop\"})\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a8db0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'product': 'gaming laptop', 'company_name': 'GameTop', 'description': 'GameTop offers free, full-version PC and mobile games with no in-game ads or malware, providing safe and enjoyable gaming experiences.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load Azure OpenAI credentials\n",
    "end_point = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT_4O_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Initialize AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=api_version,\n",
    "    azure_endpoint=end_point,\n",
    "    openai_api_key=api_key,\n",
    "    deployment_name=deployment_name,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    What is the best name to describe a company that makes {product}? \n",
    "    Just me just one single company name in plain text in one word only.\n",
    "    No explanation, title, headings etc. THe word should explain the company's product.\n",
    "    \"\"\"\n",
    ")\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, output_key=\"company_name\")\n",
    "\n",
    "# Define the second prompt (generates description)\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20-word description for the following company: {company_name}\"\n",
    ")\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, output_key=\"description\")\n",
    "\n",
    "# Create a SequentialChain\n",
    "overall_simple_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two],\n",
    "    input_variables=[\"product\"],  # Start with product\n",
    "    output_variables=[\"company_name\", \"description\"],  # Expected outputs\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "response = overall_simple_chain({\"product\": \"gaming laptop\"})\n",
    "print(response)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
